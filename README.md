# Dengue Forecasting with Explainable AI (XAI)

This project predicts **dengue disease cases** in Brazil using a **Random Forest Regression model**, and explains its predictions with **model-agnostic XAI methods** such as **SHAP** and **LIME**.

It demonstrates how explainable machine learning can help uncover relationships between **climate variables (rainfall, temperature)** and **health outcomes (dengue incidence)** â€” bridging AI and public health insight.

---

## Overview

| Component | Description |
|------------|-------------|
| **Model Type** | Random Forest Regressor (scikit-learn) |
| **XAI Methods** | SHAP (global + local), LIME (local), Partial Dependence, Feature Importance |
| **Data Source** | Historical climate and dengue case data (Brazil, CHAP-compatible format) |
| **Goal** | Forecast dengue outbreaks and interpret key climate drivers |

---

## Project Structure

XAI_regression_decisionTree/
â”‚
â”œâ”€â”€ example_data/
â”‚ â”œâ”€â”€ historic_brazil.csv # historical training data
â”‚ â””â”€â”€ future_brazil.csv # future climate data for prediction
â”‚
â”œâ”€â”€ output/
â”‚ â”œâ”€â”€ brazil_model.bin # trained model (binary)
â”‚ â””â”€â”€ predictions.csv # predicted dengue cases
â”‚
â”œâ”€â”€ shap_brazil/ # SHAP explanations
â”‚ â”œâ”€â”€ global/ # global feature importance plots
â”‚ â””â”€â”€ local/ # local instance explanations
â”‚
â”œâ”€â”€ lime_brazil/ # LIME explanations
â”‚
â”œâ”€â”€ train.py # trains Random Forest model
â”œâ”€â”€ predict.py # runs predictions using trained model
â”œâ”€â”€ XAI_brazil_forest_shap.py # local SHAP explanations
â”œâ”€â”€ XAI_brazil_forest_global.py # global SHAP analysis
â”œâ”€â”€ lime_explain_brazil.py # LIME local explanation script
â”œâ”€â”€ isolated_run.py # test script (train + predict pipeline)
â”œâ”€â”€ requirements.txt # dependencies
â””â”€â”€ README.md # project documentation

## Usage
### 1ï¸âƒ£ Train the model
python train.py example_data/historic_brazil.csv output/brazil_model.bin

### 2ï¸âƒ£ Generate predictions
python predict.py output/brazil_model.bin example_data/historic_brazil.csv example_data/future_brazil.csv output/predictions.csv

### 3ï¸âƒ£ Explain the model with SHAP
Local explanation (one instance)
```
python XAI_brazil_forest_shap.py
```
Global explanation (all data)
```
python XAI_brazil_forest_global.py
```
### 4ï¸âƒ£ Explain with LIME
```
python lime_explain_brazil.py
```
## ğŸ§© Explainable AI Methods
Method	Type	Purpose	Description
SHAP (SHapley Additive exPlanations)	Model-agnostic / Global + Local	Quantifies how each feature contributes to each prediction, ensuring consistency and additivity.	
LIME (Local Interpretable Model-agnostic Explanations)	Model-agnostic / Local	Approximates the complex model locally around one instance using a simple, interpretable model.	
Permutation Importance	Model-agnostic / Global	Measures how performance changes when a feature is randomly shuffled.	
Partial Dependence Plot (PDP)	Model-agnostic / Global	Shows how predicted outcomes change as one or two features vary.	
## Example Outputs

### SHAP Summary (Global)

Shows which climate features most influence dengue predictions.

### SHAP Dependence Plot

Visualizes interaction between rainfall and mean temperature.

### LIME Local Explanation

Explains why the model predicted a specific value.

## Interpretation Highlights

Rainfall generally increases predicted dengue cases when above seasonal averages.

Mean temperature influences dengue transmission risk non-linearly (moderate temps amplify mosquito activity).

Model explanations allow local health authorities to prioritize surveillance and intervention based on climate forecasts.

## Technologies Used
Category	Tools
Programming	Python 3.10+
ML Framework	scikit-learn
Explainability	SHAP, LIME
Visualization	matplotlib
Data Handling	pandas, numpy 

### Research Relevance

This project demonstrates interpretable forecasting in the climate-health domain.
It aligns with the CHAP (Climate and Health Analytics Platform) initiative and provides a reproducible framework for explainable regression models in epidemiological applications.